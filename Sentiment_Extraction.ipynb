{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W2pmNadvonZi",
        "xnVpV1iaHchm",
        "TWjOixtiwMN_"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA603 Big Data Processing Project \n",
        "Group 3: Pooja Kangokar Pranesh, Yun-Zih Chen, Elizabeth Cardosa\n",
        "\n",
        "The goal of this project is leverage big data technologies to train a model using the UCI ML Drug Review dataset to predict the star rating of drug based on the sentiment of the review. This model will then perform inference in a streaming manner on ‘real-time’ reviews coming in. This application can then be used to help potential customers understand the overall sentiment towards a drug and if it might be useful for them. \n"
      ],
      "metadata": {
        "id": "f6WifCaLDGcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOjNnpYbBbOO",
        "outputId": "b20b1ef7-e7be-46d2-f4f9-3e5cc7b19096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "working_folder = \"/content/drive/My Drive/UMBC Fall 2022/DATA603 Big Data Processing/Project/Data/\""
      ],
      "metadata": {
        "id": "PIZxklXOCF68"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries and Dependencies"
      ],
      "metadata": {
        "id": "XmKrGUucF-Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"!pip install -qq pyspark \n",
        "!pip install -qq spark-nlp \n",
        "!pip install -qq findspark \"\"\""
      ],
      "metadata": {
        "id": "gHK-NoIfCF-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c307a074-0e08-48b7-ae26-573c5fd531ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!pip install -qq pyspark \\n!pip install -qq spark-nlp \\n!pip install -qq findspark '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -qq pyspark==3.2.1 spark-nlp findspark #pyspark==3.1.2 spark-nlp findspark"
      ],
      "metadata": {
        "id": "-x6Yo--BrPS5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYAw63LcIV0n",
        "outputId": "048cc8be-9bfd-4738-9547-a5faadaaa261"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-28 02:29:17--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-11-28 02:29:17--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-11-28 02:29:17--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "\r-                     0%[                    ]       0  --.-KB/s               \rInstalling PySpark 3.2.1 and Spark NLP 4.2.3\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-28 02:29:17 (62.0 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "setup Colab for PySpark 3.2.1 and Spark NLP 4.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.pandas as ps\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXvkRIb6DFc3",
        "outputId": "dbe659e5-dfd8-4e53-ec64-a152f98e350e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext"
      ],
      "metadata": {
        "id": "aO-Tc6NMDRRn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *"
      ],
      "metadata": {
        "id": "EgK1m0ALC_Yi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Check Spark Session Information\n",
        "spark\"\"\""
      ],
      "metadata": {
        "id": "naR3cF8gvebO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9aa356ae-80ba-4d81-86c4-661e991a4cc3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Import SparkSession\\nfrom pyspark.sql import SparkSession\\n# Create a Spark Session\\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()\\n# Check Spark Session Information\\nspark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpep-Y83IgNN",
        "outputId": "e17ae11c-7fda-4d4e-c6f0-41b65f013a4d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version: 4.2.3\n",
            "Apache Spark version: 3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext.getOrCreate();"
      ],
      "metadata": {
        "id": "MrG8uo1zjfU2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read-in Dataset\n"
      ],
      "metadata": {
        "id": "ll9VMsHzGDOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29\n"
      ],
      "metadata": {
        "id": "W2pmNadvonZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset provides patient reviews on specific drugs along with related conditions and a 10 star patient rating reflecting overall patient satisfaction. The data was obtained by crawling online pharmaceutical review sites. The intention was to study\n",
        "\n",
        "- sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,\n",
        "- the transferability of models among domains, i.e. conditions, and\n",
        "- the transferability of models among different data sources (see 'Drug Review Dataset (Druglib.com)').\n",
        "\n",
        "The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively.\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1. drugName (categorical): name of drug\n",
        "2. condition (categorical): name of condition\n",
        "3. review (text): patient review\n",
        "4. rating (numerical): 10 star patient rating\n",
        "5. date (date): date of review entry\n",
        "6. usefulCount (numerical): number of users who found review useful\n"
      ],
      "metadata": {
        "id": "ZXFtRQpRoiom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important notes:\n",
        "\n",
        "When using this dataset, you agree that you\n",
        "1. only use the data for research purposes\n",
        "2. don't use the data for any commerical purposes\n",
        "3. don't distribute the data to anyone else\n",
        "4. cite us\n",
        "\n",
        "Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI: [Web Link] "
      ],
      "metadata": {
        "id": "0xOlCh2ISk6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in Test Data"
      ],
      "metadata": {
        "id": "xnVpV1iaHchm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in training data file\n",
        "customschema = StructType([\n",
        "  StructField(\"UniqueID\", IntegerType(), True)\n",
        "  ,StructField(\"drugName\", StringType(), True)\n",
        "  ,StructField(\"condition\", StringType(), True)\n",
        "  ,StructField(\"review\", StringType(), True)\n",
        "  ,StructField(\"rating\", DoubleType(), True)\n",
        "  ,StructField(\"date\", StringType(), True)\n",
        "  ,StructField(\"usefulCount\", IntegerType(), True)\n",
        "  ])"
      ],
      "metadata": {
        "id": "o4220ehFHerX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = spark.read.format(\"csv\")\\\n",
        "           .option(\"delimiter\", \"\\t\")\\\n",
        "           .option(\"header\", \"true\")\\\n",
        "           .option(\"quote\", \"\\\"\")\\\n",
        "           .option(\"escape\", \"\\\"\")\\\n",
        "           .option(\"multiLine\",\"true\")\\\n",
        "           .option(\"quoteMode\",\"ALL\")\\\n",
        "           .option(\"mode\",\"PERMISSIVE\")\\\n",
        "           .option(\"ignoreLeadingWhiteSpace\",\"true\")\\\n",
        "           .option(\"ignoreTrailingWhiteSpace\",\"true\")\\\n",
        "           .option(\"parserLib\",\"UNIVOCITY\")\\\n",
        "           .schema(customschema)\\\n",
        "           .load(working_folder + \"drugsComTest_raw.tsv\")"
      ],
      "metadata": {
        "id": "prmAhNSIHiZ5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.count()"
      ],
      "metadata": {
        "id": "yUfc5E3WpH3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.show(5)"
      ],
      "metadata": {
        "id": "tHClVhv7HmUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in and Explore Training Data"
      ],
      "metadata": {
        "id": "a6Ky5tG_HWjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in training data file\n",
        "customschema = StructType([\n",
        "  StructField(\"UniqueID\", IntegerType(), True)\n",
        "  ,StructField(\"drugName\", StringType(), True)\n",
        "  ,StructField(\"condition\", StringType(), True)\n",
        "  ,StructField(\"review\", StringType(), True)\n",
        "  ,StructField(\"rating\", DoubleType(), True)\n",
        "  ,StructField(\"date\", StringType(), True)\n",
        "  ,StructField(\"usefulCount\", IntegerType(), True)\n",
        "  ])\n",
        "\n",
        "df = spark.read.format(\"csv\")\\\n",
        "           .option(\"delimiter\", \"\\t\")\\\n",
        "           .option(\"header\", \"true\")\\\n",
        "           .option(\"quote\", \"\\\"\")\\\n",
        "           .option(\"escape\", \"\\\"\")\\\n",
        "           .option(\"multiLine\",\"true\")\\\n",
        "           .option(\"quoteMode\",\"ALL\")\\\n",
        "           .option(\"mode\",\"PERMISSIVE\")\\\n",
        "           .option(\"ignoreLeadingWhiteSpace\",\"true\")\\\n",
        "           .option(\"ignoreTrailingWhiteSpace\",\"true\")\\\n",
        "           .option(\"parserLib\",\"UNIVOCITY\")\\\n",
        "           .schema(customschema)\\\n",
        "           .load(working_folder + \"drugsComTrain_raw.tsv\")"
      ],
      "metadata": {
        "id": "9WMlYS-iCGEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "nocaGG4bfmex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "id": "Bz0g5aqDCPo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd_df = df.toPandas()"
      ],
      "metadata": {
        "id": "7yi94MRQrDYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean Training Dataset"
      ],
      "metadata": {
        "id": "H9GiOXX5tEC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with null columns\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "HuT9_OH2tlXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "D--LA1MOtzy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop conditions with </span> tag\n",
        "df = df.where(~df.condition.contains(\"</span>\"))"
      ],
      "metadata": {
        "id": "mxu3UXTtt3gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "0J6qI90AtlfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('rating').count().orderBy(\"rating\", ascending=False).show()"
      ],
      "metadata": {
        "id": "tuW5_k7sjMBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average Star Rating by Condition\n",
        "df.groupBy(\"condition\").agg({'rating':'avg', 'condition':'count'}).orderBy(\"count(condition)\",ascending=False).show()"
      ],
      "metadata": {
        "id": "UHd2umUipOSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average Star Rating by Drug Name \n",
        "df.groupBy(\"drugName\").agg({'rating':'avg', 'drugName':'count'}).orderBy(\"count(drugName)\",ascending=False).show()"
      ],
      "metadata": {
        "id": "nj9UGIQ1pTtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df_train = df.toPandas()"
      ],
      "metadata": {
        "id": "HcAbAugiXBJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df_train.to_csv(\"testing.csv\")"
      ],
      "metadata": {
        "id": "p8bB22h132JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import py4j.protocol  \n",
        "from py4j.protocol import Py4JJavaError  \n",
        "from py4j.java_gateway import JavaObject  \n",
        "from py4j.java_collections import JavaArray, JavaList\n",
        "\n",
        "from pyspark import RDD, SparkContext  \n",
        "from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n",
        "\n",
        "\n",
        "# Helper function to convert python object to Java objects\n",
        "def _to_java_object_rdd(rdd):  \n",
        "    \"\"\" Return a JavaRDD of Object by unpickling\n",
        "    It will convert each Python object into Java object by Pyrolite, whenever the\n",
        "    RDD is serialized in batch or not.\n",
        "    \"\"\"\n",
        "    rdd = rdd._reserialize(AutoBatchedSerializer(PickleSerializer()))\n",
        "    return rdd.ctx._jvm.org.apache.spark.mllib.api.python.SerDe.pythonToJava(rdd._jrdd, True)\n",
        "\n",
        "# First you have to convert it to an RDD \n",
        "JavaObj = _to_java_object_rdd(df.rdd)\n",
        "\n",
        "# Now we can run the estimator\n",
        "sc._jvm.org.apache.spark.util.SizeEstimator.estimate(JavaObj)"
      ],
      "metadata": {
        "id": "dA6EwZul4e74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use John Snow Labs pretrained sentiment models pipeline\n"
      ],
      "metadata": {
        "id": "ouSfCBo-RgH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://nlp.johnsnowlabs.com/\n",
        "\n",
        "Medium Article: \n",
        "https://medium.com/analytics-vidhya/sentiment-analysis-with-sparknlp-couldnt-be-easier-2a8ea3b728a0\n",
        "\n",
        "John Snow Labs Reference Notebook: \n",
        "https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/quick_start_google_colab.ipynb#scrollTo=tyMMD_upEfIa\n",
        "\n",
        "This model using BioBERT would potentially perform better, but it is not free-tier:\n",
        "https://nlp.johnsnowlabs.com/2022/07/28/bert_sequence_classifier_drug_reviews_webmd_en_3_0.html\n"
      ],
      "metadata": {
        "id": "ZWvfTpUkyEms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Twitter Sentiment Analysis Model: analyze_sentimentdl_use_twitter \n",
        "\n",
        "Model: https://nlp.johnsnowlabs.com/2021/01/18/sentimentdl_use_twitter_en.html\n",
        "\n",
        "Universal Sentence Encoder: https://nlp.johnsnowlabs.com/2020/04/17/tfhub_use.html"
      ],
      "metadata": {
        "id": "TWjOixtiwMN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"pipeline = PretrainedPipeline('analyze_sentimentdl_use_twitter', 'en')\n",
        "pipeline.model.stages\n",
        "# rename the text column as 'text', pipeline expects 'text' \n",
        "df_result = pipeline.transform(df.withColumnRenamed(\"review\", \"text\"))\n",
        "# Extract results from the \"sentiments\" column\n",
        "df_twitter_sentiments = df_result.withColumn(\"sentiment\", explode('sentiment.result')).drop(*['document','sentence_embeddings'])\"\"\""
      ],
      "metadata": {
        "id": "o7wglGlsIhh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A vast majority of the reviews are negative\n",
        "\n",
        "\n",
        "+---------+------+<br>\n",
        "|sentiment| count|<br>\n",
        "+---------+------+<br>\n",
        "| positive| 31299|<br>\n",
        "|  neutral|  6568|<br>\n",
        "| negative|123430|<br>\n",
        "+---------+------+\n",
        "\n"
      ],
      "metadata": {
        "id": "bC0vUff43jzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# took 20 minutes to run\n",
        "#df_twitter_sentiments.groupBy('sentiment').count().show()"
      ],
      "metadata": {
        "id": "VhzZJ2UJLtKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use RoBERTa Sentiment Classifier: roberta_classifier_autotrain_sentiment_polarity_918130222\n",
        "\n",
        "Model: https://nlp.johnsnowlabs.com/2022/09/19/roberta_classifier_autotrain_sentiment_polarity_918130222_en.html\n",
        "\n",
        "HuggingFace: https://huggingface.co/docs/transformers/model_doc/roberta\n",
        "\n",
        "Breakdown how pretrained pipeline works under the hood: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN.ipynb"
      ],
      "metadata": {
        "id": "dsCoFFk4k-4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"review\") \\\n",
        "        .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "seq_classifier = RoBertaForSequenceClassification.pretrained(\"roberta_classifier_autotrain_sentiment_polarity_918130222\",\"en\") \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setOutputCol(\"class\")"
      ],
      "metadata": {
        "id": "Hq1cuAU8sdFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline = Pipeline(stages=[documentAssembler, tokenizer, seq_classifier])"
      ],
      "metadata": {
        "id": "oUnFUal6u65i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train = pipeline.fit(df.withColumnRenamed(\"review\", \"text\")).transform(df.withColumnRenamed(\"review\", \"text\"))\n",
        "df_train = nlp_pipeline.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "-LH4DYPty3QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.withColumn(\"sentiment\", explode('class.result')).drop('document','token','class')"
      ],
      "metadata": {
        "id": "BYq2VfmA5nfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.show()"
      ],
      "metadata": {
        "id": "W7mJdiulCWc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.sentiment.cast(IntegerType())"
      ],
      "metadata": {
        "id": "wpjCNbUyD1wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.show()"
      ],
      "metadata": {
        "id": "_GhrFM99CyJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First you have to convert it to an RDD \n",
        "JavaObj = _to_java_object_rdd(df_train.rdd)\n",
        "\n",
        "# Now we can run the estimator\n",
        "sc._jvm.org.apache.spark.util.SizeEstimator.estimate(JavaObj)"
      ],
      "metadata": {
        "id": "RpyoXnCm5Bo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.write.mode('overwrite').parquet(working_folder + \"drug_reviews_with_sentiment_train.parquet\")"
      ],
      "metadata": {
        "id": "Cb62xy1d15eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write complete dataframe to disk\n",
        "#pd_df_train = df_train.toPandas()"
      ],
      "metadata": {
        "id": "8iY898cGHpaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd_df_train.to_csv(working_folder + \"drug_reviews_with_sentiment_train.csv\")"
      ],
      "metadata": {
        "id": "9condL2x0pkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "df_test = df_test.dropna()"
      ],
      "metadata": {
        "id": "H0O6sDDxl2Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop rows where condition contains irrelevant strings\n",
        "df_test = df_test.where(~df_test.condition.contains(\"</span>\"))"
      ],
      "metadata": {
        "id": "fHWRSqmfugPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.count()"
      ],
      "metadata": {
        "id": "dXbFhJaJ0UJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pipeline.fit(df_test).transform(df_test)"
      ],
      "metadata": {
        "id": "6dAKII66DzEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test.withColumn(\"sentiment\", explode('class.result')).drop(*['token','class','document'])"
      ],
      "metadata": {
        "id": "b2S1eRj0D5CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.show()"
      ],
      "metadata": {
        "id": "AORVs6_AmIeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write complete dataframe to disk\n",
        "#df_test.write.csv(working_folder + \"drug_reviews_with_sentiment_test.csv\")\n",
        "#df_test.toPandas().to_csv(working_folder + \"drug_reviews_with_sentiment_test.csv\")\n",
        "df_test.write.mode('overwrite').parquet(working_folder + \"drug_reviews_with_sentiment_test.parquet\")"
      ],
      "metadata": {
        "id": "ss1zGIvsCznx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}